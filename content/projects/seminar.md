---
title: "Self-supervised cross modality representation learning"
description: Details of seminar
timeline: Jan 2020 to May 2020
guidance: Prof. Preethi Jyothi and Prof. Ganesh Ramakrishnan
date: "2020-05-31T19:25:30+02:00"
publishDate: "2020-05-31T19:25:30+02:00"
---

The seminar has focused around multi-modal learning and how self-supervised objectives learn better embeddings. 

<!--more-->
In this work, we learn and critique various self-supervised learning techniques.


#### **Responsibilities :**

- Explored self-supervised representation learning for unimodal (like BERT, PASE) and multimodal setting (like ViLBERT, LXMERT, UNITER)
- Understood the nuances of pre-training in feature learning
- Suggested audio-linguistic feature representation, that gave 5.6% improvement on IoU= 0.7 metric
- **Technologies:** Python and PyTorch

{{< links "#" "#" "#" >}}