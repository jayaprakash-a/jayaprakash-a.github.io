<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Jayaprakash Akula</title>
    <link>https://jayaprakash-a.github.io/</link>
    <description>Recent content on Jayaprakash Akula</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Jul 2021 19:25:30 +0200</lastBuildDate><atom:link href="https://jayaprakash-a.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cross Lingual Video and Text Retrieval: A New Benchmark Dataset and Algorithm</title>
      <link>https://jayaprakash-a.github.io/publications/icmi2021/</link>
      <pubDate>Wed, 28 Jul 2021 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/publications/icmi2021/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Brief Abstract:&lt;/strong&gt; Video retrieval using natural language queries requires learning semantically meaningful joint embeddings between the text and the audio-visual input.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Cross-Modal learning for Audio-Visual Video Parsing</title>
      <link>https://jayaprakash-a.github.io/publications/interspeech2021/</link>
      <pubDate>Tue, 06 Jul 2021 00:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/publications/interspeech2021/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Brief Abstract:&lt;/strong&gt; In this paper, we present a novel approach to the audio-visual video parsing (AVVP) task that demarcates events from a video separately for audio and visual modalities.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Self supervised audio-visual learning</title>
      <link>https://jayaprakash-a.github.io/projects/masters_thesis/</link>
      <pubDate>Fri, 30 Apr 2021 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/projects/masters_thesis/</guid>
      <description>&lt;p&gt;The thesis has revolved around multi-modal learning and how self-supervised objectives learn better embeddings.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Investigating self-supervised architectures for learning speech representations</title>
      <link>https://jayaprakash-a.github.io/projects/iitb_rnd/</link>
      <pubDate>Sun, 31 May 2020 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/projects/iitb_rnd/</guid>
      <description>&lt;p&gt;In this project I along with my research group have explored various audio encoders.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Self-supervised cross modality representation learning</title>
      <link>https://jayaprakash-a.github.io/projects/seminar/</link>
      <pubDate>Sun, 31 May 2020 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/projects/seminar/</guid>
      <description>&lt;p&gt;The seminar has focused around multi-modal learning and how self-supervised objectives learn better embeddings.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Caption Alignment for Low Resource Audio-Visual Data</title>
      <link>https://jayaprakash-a.github.io/publications/interspeech2020/</link>
      <pubDate>Fri, 25 Oct 2019 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/publications/interspeech2020/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Brief Abstract:&lt;/strong&gt; Understanding videos via captioning has gained a lot of traction recently.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Sahayatra Android App</title>
      <link>https://jayaprakash-a.github.io/projects/bachelor_thesis/</link>
      <pubDate>Tue, 30 Apr 2019 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/projects/bachelor_thesis/</guid>
      <description>&lt;p&gt;I have worked on developing a robust and open-source ride dispatch application.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Chat bot and Voice banking service</title>
      <link>https://jayaprakash-a.github.io/internships/iexceed_intern/</link>
      <pubDate>Thu, 31 May 2018 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/internships/iexceed_intern/</guid>
      <description>&lt;p&gt;I-exceed is a digital transformation partner for leading financial institutions worldwide.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>FOSSEE Summer Internship</title>
      <link>https://jayaprakash-a.github.io/internships/iitb_intern/</link>
      <pubDate>Wed, 31 May 2017 19:25:30 +0200</pubDate>
      
      <guid>https://jayaprakash-a.github.io/internships/iitb_intern/</guid>
      <description>&lt;p&gt;Xcos is a Scilab tool dedicated to the modeling and simulation of hybrid dynamic systems including both continuous and discrete models.&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
